{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "Manual Features\n",
      "LASSO\n",
      "search complete\n",
      "search complete\n",
      "search complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "import dask\n",
    "import dask.threaded\n",
    "from dask import delayed\n",
    "\n",
    "# Load your feature datasets\n",
    "pca = pd.read_csv(\"PCA_features.csv\")\n",
    "mf = pd.read_csv(\"manual_features.csv\")\n",
    "lasso = pd.read_csv(\"LASSO_features.csv\")\n",
    "res = pd.read_csv(\"response.csv\")\n",
    "\n",
    "# Define a list of feature datasets\n",
    "feature_datasets = [(\"PCA\", pca), (\"Manual Features\", mf), (\"LASSO\", lasso)]\n",
    "\n",
    "# Load the response variable\n",
    "y = res['avg_salary']\n",
    "\n",
    "# Initialize an empty dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Define a delayed function for the randomized search\n",
    "@delayed\n",
    "def perform_randomized_search(dataset_name, data, y):\n",
    "    print(dataset_name)\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize the RandomForestRegressor\n",
    "    rf_regressor = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # Define hyperparameter search space for n_estimators\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(1, 501),\n",
    "    }\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Perform RandomizedSearchCV to find the best hyperparameters\n",
    "    random_search = RandomizedSearchCV(rf_regressor, param_distributions=param_dist, n_iter=100, \n",
    "                                       scoring='neg_mean_squared_error', cv=kf, random_state=42)\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_rf_model = random_search.best_estimator_\n",
    "    \n",
    "    print(\"search complete\")\n",
    "    \n",
    "    # Calculate cross-validation RMSE and MAE scores\n",
    "    cv_rmse_scores = np.sqrt(-cross_val_score(best_rf_model, data, y, cv=kf, scoring='neg_mean_squared_error'))\n",
    "    cv_mae_scores = -cross_val_score(best_rf_model, data, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = best_rf_model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE and MAE on the test set\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"Best Hyperparameters\": random_search.best_params_,\n",
    "        \"Cross-Validation RMSE Scores\": cv_rmse_scores,\n",
    "        \"Mean Cross-Validation RMSE\": cv_rmse_scores.mean(),\n",
    "        \"Cross-Validation MAE Scores\": cv_mae_scores,\n",
    "        \"Mean Cross-Validation MAE\": cv_mae_scores.mean(),\n",
    "        \"RMSE on Test Set\": rmse,\n",
    "        \"MAE on Test Set\": mae\n",
    "    }\n",
    "\n",
    "# Create a list of delayed tasks for each feature dataset\n",
    "delayed_tasks = [perform_randomized_search(name, data, y) for name, data in feature_datasets]\n",
    "\n",
    "# Compute the delayed tasks in parallel\n",
    "results_list = dask.compute(*delayed_tasks, scheduler='threads')\n",
    "\n",
    "# Store results in the dictionary\n",
    "for result in results_list:\n",
    "    results[result[\"dataset_name\"]] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'dataset_name': 'PCA', 'Best Hyperparameters': {'n_estimators': 92}, 'Cross-Validation RMSE Scores': array([19.61316201, 20.21878848, 21.07849338, 23.4958912 , 18.13905775,\n",
      "       13.99408958, 23.86541004, 19.30725082, 20.23802092, 20.99772217]), 'Mean Cross-Validation RMSE': 20.094788636129525, 'Cross-Validation MAE Scores': array([12.88797101, 12.7015942 , 12.56720035, 13.12264982, 12.05552291,\n",
      "        9.73545828, 14.1586369 , 11.27511751, 13.71276439, 13.7363396 ]), 'Mean Cross-Validation MAE': 12.595325499412457, 'RMSE on Test Set': 20.07725366017056, 'MAE on Test Set': 12.710388094543331}, {'dataset_name': 'Manual Features', 'Best Hyperparameters': {'n_estimators': 202}, 'Cross-Validation RMSE Scores': array([17.71855795, 18.65275495, 22.66868323, 23.79715823, 18.01544619,\n",
      "       13.38410002, 23.84151786, 14.93435742, 20.57037174, 16.76614498]), 'Mean Cross-Validation RMSE': 19.03490925674156, 'Cross-Validation MAE Scores': array([11.22171617, 10.88023102, 14.50876371, 13.26846401, 11.06007493,\n",
      "        9.35476318, 14.2052783 ,  9.0351552 , 13.49401258, 12.52177549]), 'Mean Cross-Validation MAE': 11.955023459102666, 'RMSE on Test Set': 17.39664868427775, 'MAE on Test Set': 11.075902053292577}, {'dataset_name': 'LASSO', 'Best Hyperparameters': {'n_estimators': 54}, 'Cross-Validation RMSE Scores': array([18.34973433, 20.84260152, 19.38120645, 22.23479131, 18.36167181,\n",
      "       13.14909657, 25.42735444, 17.98877546, 19.88963327, 17.46993225]), 'Mean Cross-Validation RMSE': 19.309479741222145, 'Cross-Validation MAE Scores': array([11.68993573, 12.11752361, 13.39865426, 12.66861334, 11.16305904,\n",
      "        9.42312814, 15.04476833, 10.41129517, 12.8744747 , 11.89645191]), 'Mean Cross-Validation MAE': 12.068790423635331, 'RMSE on Test Set': 19.673274182263718, 'MAE on Test Set': 12.157257800923908})\n"
     ]
    }
   ],
   "source": [
    "print(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features Ranked by Importance for PCA:\n",
      "Principal_Component_3: 0.1599\n",
      "is_senior: 0.1012\n",
      "Principal_Component_9: 0.0774\n",
      "Principal_Component_17: 0.0565\n",
      "python_yn: 0.0558\n",
      "Principal_Component_2: 0.0512\n",
      "Principal_Component_12: 0.0398\n",
      "Principal_Component_10: 0.0395\n",
      "Principal_Component_18: 0.0355\n",
      "Principal_Component_14: 0.0345\n",
      "\n",
      "\n",
      "Top 10 Features Ranked by Importance for Manual Features:\n",
      "job_title_analyst: 0.1297\n",
      "hourly: 0.1263\n",
      "is_senior: 0.1077\n",
      "HQ_Longitude: 0.0675\n",
      "Longitude: 0.0637\n",
      "job_title_director: 0.0496\n",
      "desc_len: 0.0492\n",
      "Log_Population: 0.0462\n",
      "Rating: 0.0445\n",
      "age: 0.0383\n",
      "\n",
      "\n",
      "Top 10 Features Ranked by Importance for LASSO Features:\n",
      "is_senior: 0.1270\n",
      "job_simp_analyst: 0.1167\n",
      "Rating: 0.1024\n",
      "job_state_CA: 0.0775\n",
      "python_yn: 0.0597\n",
      "job_simp_director: 0.0431\n",
      "Sector_Health Care: 0.0310\n",
      "Industry_Health Care Services & Hospitals: 0.0248\n",
      "Job Title_Director II, Data Science - GRM Actuarial: 0.0217\n",
      "Industry_Enterprise Software & Network Solutions: 0.0209\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to print the top n features by importance\n",
    "def print_top_features(importances, feature_names, top_n=10):\n",
    "    feature_importance = list(zip(feature_names, importances))\n",
    "    feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    for feature, importance in feature_importance[:top_n]:\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Define hyperparameters for each dataset\n",
    "hyperparameters = {\n",
    "    'PCA': {'n_estimators': 92},\n",
    "    'Manual Features': {'n_estimators': 202},\n",
    "    'LASSO Features': {'n_estimators': 54}\n",
    "}\n",
    "\n",
    "# Iterate through each dataset\n",
    "for dataset_name, data in [(\"PCA\", pca), (\"Manual Features\", mf), (\"LASSO Features\", lasso)]:\n",
    "    # Split the data\n",
    "    X_train, _, y_train, _ = train_test_split(data, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a RandomForestRegressor with the specified hyperparameters\n",
    "    random_forest_regressor = RandomForestRegressor(\n",
    "        n_estimators=hyperparameters[dataset_name]['n_estimators'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Fit the Random Forest model\n",
    "    random_forest_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Print the top 10 features by importance\n",
    "    print(f\"Top 10 Features Ranked by Importance for {dataset_name}:\")\n",
    "    print_top_features(random_forest_regressor.feature_importances_, data.columns, top_n=10)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
